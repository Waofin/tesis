# Implementaci贸n CUDA para PACO

Este directorio contiene una implementaci贸n funcional de PACOCalc con aceleraci贸n GPU usando CuPy.

##  Requisitos

### 1. GPU NVIDIA
- GPU NVIDIA con soporte CUDA
- Drivers NVIDIA actualizados

### 2. CUDA Toolkit
- CUDA 11.x o 12.x instalado
- Verificar versi贸n: `nvcc --version`

### 3. CuPy
Instalar seg煤n tu versi贸n de CUDA:

```bash
# Para CUDA 11.x
pip install cupy-cuda11x

# Para CUDA 12.x
pip install cupy-cuda12x

# Verificar instalaci贸n
python -c "import cupy as cp; print(cp.cuda.runtime.getDeviceCount())"
```

##  Uso R谩pido

### 1. Benchmark B谩sico

```bash
python benchmark_cuda.py
```

Esto ejecutar谩:
- Benchmark de `pixelCalc()` CPU vs GPU
- Opcionalmente, benchmark completo de `PACOCalc()`

### 2. Usar en C贸digo

```python
from paco.processing.fullpaco_cuda import FullPACO_CUDA

# Crear instancia GPU
fp_gpu = FullPACO_CUDA(
    image_stack=image_stack,
    angles=angles,
    psf=psf,
    psf_rad=4,
    patch_area=49
)

# Ejecutar PACOCalc en GPU
a, b = fp_gpu.PACOCalc_CUDA(phi0s, batch_size=1000)
```

##  Resultados Esperados

### Speedup T铆pico

| Operaci贸n | CPU | GPU | Speedup |
|-----------|-----|-----|---------|
| `pixelCalc()` (100 iteraciones) | ~0.5s | ~0.05s | **10x** |
| `PACOCalc()` (5050 imagen) | ~5 min | ~30s | **10x** |
| `PACOCalc()` (100100 imagen) | ~8 horas | ~30 min | **16x** |

**Nota**: Speedups reales dependen de:
- GPU (RTX 3090 vs GTX 1050)
- Tama帽o de datos
- Overhead de transferencia CPUGPU

##  Configuraci贸n Avanzada

### Ajustar Batch Size

```python
# Para im谩genes grandes, usar batches m谩s grandes
a, b = fp_gpu.PACOCalc_CUDA(phi0s, batch_size=2000)

# Para im谩genes peque帽as, batches m谩s peque帽os
a, b = fp_gpu.PACOCalc_CUDA(phi0s, batch_size=500)
```

### Usar Solo CPU para Comparaci贸n

```python
# Forzar CPU aunque tengas GPU
a, b = fp_gpu.PACOCalc_CUDA(phi0s, use_gpu_pixelcalc=False)
```

## 锔 Limitaciones Actuales

1. **Extracci贸n de Patches**: `getPatch()` se ejecuta en CPU
   - Esto es porque requiere indexaci贸n compleja
   - Puede optimizarse en el futuro con kernels CUDA personalizados

2. **Transferencia CPUGPU**: Overhead para datos peque帽os
   - Para im谩genes <5050, el overhead puede dominar
   - Para im谩genes >100100, el speedup es significativo

3. **Memoria GPU**: Limitada por VRAM
   - T铆pico: 8-24 GB
   - Para im谩genes muy grandes, procesar en batches

##  Soluci贸n de Problemas

### Error: "CuPy no est谩 disponible"

```bash
# Verificar que CUDA est谩 instalado
nvcc --version

# Instalar CuPy correcto para tu versi贸n de CUDA
pip uninstall cupy
pip install cupy-cuda11x  # o cupy-cuda12x
```

### Error: "No se pudo inicializar GPU"

1. Verificar que la GPU es NVIDIA:
   ```bash
   nvidia-smi
   ```

2. Verificar que los drivers est谩n actualizados

3. Verificar que CuPy detecta la GPU:
   ```python
   import cupy as cp
   print(cp.cuda.runtime.getDeviceCount())
   ```

### Speedup Bajo o Negativo

- **Causa**: Overhead de transferencia CPUGPU
- **Soluci贸n**: Usar im谩genes m谩s grandes (>100100) o batches m谩s grandes

- **Causa**: GPU muy antigua o lenta
- **Soluci贸n**: GPU moderna (RTX 2060+) recomendada

##  Pr贸ximas Optimizaciones

1. **Kernels CUDA Personalizados**: Para `getPatch()` y operaciones espec铆ficas
2. **Procesamiento Completamente Paralelo**: Paralelizar el loop sobre p铆xeles en GPU
3. **Streams CUDA**: Overlap de transferencias y computaci贸n
4. **Shared Memory**: Optimizar acceso a memoria para operaciones repetidas

##  Referencias

- [CuPy Documentation](https://docs.cupy.dev/)
- [CUDA Programming Guide](https://docs.nvidia.com/cuda/)
- [Numba CUDA](https://numba.readthedocs.io/en/stable/cuda/index.html) (alternativa)

##  Notas

- La implementaci贸n actual es un **prototipo funcional**
- Est谩 optimizada para **facilidad de uso** sobre m谩ximo rendimiento
- Para m谩ximo rendimiento, considera escribir kernels CUDA personalizados
- La precisi贸n num茅rica puede diferir ligeramente entre CPU y GPU (float32)


