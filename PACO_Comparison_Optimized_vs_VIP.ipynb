{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación PACO Optimizado vs VIP (con PyTorch GPU)\n",
        "\n",
        "Este notebook compara:\n",
        "1. **PACO-master Optimizado (CPU)**: Versión con optimizaciones de vectorización, scipy.linalg.inv() y paralelización\n",
        "2. **PACO-master PyTorch GPU**: Versión optimizada con PyTorch para aceleración GPU (ideal para Colab)\n",
        "3. **VIP-master PACO**: Implementación de PACO en el paquete VIP\n",
        "\n",
        "## Optimizaciones Implementadas\n",
        "\n",
        "Según el análisis en `5resultados.tex`:\n",
        "\n",
        "### CPU Optimizations:\n",
        "1. **Vectorización de sampleCovariance()**: Reemplazo de list comprehension con operaciones vectorizadas (speedup ~4.9×)\n",
        "2. **Optimización de inversión de matrices**: Uso de `scipy.linalg.inv()` con regularización (speedup ~1.6×)\n",
        "3. **Paralelización del loop principal**: Uso de `joblib` con backend `threading` (speedup ~8×)\n",
        "4. **Speedup total combinado estimado (CPU)**: ~15.4×\n",
        "\n",
        "### GPU Optimizations (PyTorch):\n",
        "- **Procesamiento batch en GPU**: Procesa miles de píxeles simultáneamente\n",
        "- **Operaciones matriciales optimizadas**: PyTorch usa cuBLAS/cuDNN para máximo rendimiento\n",
        "- **Speedup esperado (GPU)**: 50-200× vs CPU secuencial (depende de GPU: T4, A100, L4)\n",
        "\n",
        "## Configuración para Colab\n",
        "\n",
        "### Opción A: Archivos desde Google Drive (Recomendado)\n",
        "1. **Subir PACO-master a Drive**: Sube la carpeta completa a tu Google Drive\n",
        "2. **Ejecutar celdas 0.1-0.4**: Montar Drive y copiar archivos\n",
        "3. **Seleccionar GPU**: Runtime > Change runtime type > Hardware accelerator: GPU\n",
        "4. **GPU recomendada**: A100 (más rápida) o T4 (gratis, más lenta pero aún muy rápida)\n",
        "5. **RAM amplia**: Activar \"High RAM\" si procesas imágenes grandes\n",
        "\n",
        "### Opción B: Archivos desde GitHub\n",
        "1. Clonar repositorio directamente en Colab\n",
        "2. Seguir con las celdas de importación normales\n",
        "\n",
        "## Autor\n",
        "César Cerda - Universidad del Bío-Bío\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Configuración Inicial - Cargar desde Google Drive\n",
        "\n",
        "Si tus archivos están en Google Drive, ejecuta las siguientes celdas para montar Drive y configurar los paths.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Montar Google Drive\n",
        "# Esta celda abrirá una ventana para autorizar el acceso a Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Drive en /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"✓ Google Drive montado correctamente\")\n",
        "print(f\"  Path: /content/drive/MyDrive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar path a tus archivos en Drive\n",
        "# AJUSTA ESTA RUTA según donde tengas PACO-master en tu Drive\n",
        "\n",
        "# Opción 1: Si PACO-master está directamente en MyDrive\n",
        "DRIVE_PACO_PATH = '/content/drive/MyDrive/PACO-master'\n",
        "\n",
        "# Opción 2: Si está en una subcarpeta (ajusta según tu estructura)\n",
        "# DRIVE_PACO_PATH = '/content/drive/MyDrive/Tesis/PACO-master'\n",
        "# DRIVE_PACO_PATH = '/content/drive/MyDrive/Colab Notebooks/PACO-master'\n",
        "\n",
        "# Verificar que existe\n",
        "from pathlib import Path\n",
        "paco_path = Path(DRIVE_PACO_PATH)\n",
        "\n",
        "if paco_path.exists():\n",
        "    print(f\"✓ PACO-master encontrado en: {DRIVE_PACO_PATH}\")\n",
        "    print(f\"  Contenido: {list(paco_path.iterdir())[:5]}...\")  # Mostrar primeros 5 items\n",
        "else:\n",
        "    print(f\"⚠ No se encontró PACO-master en: {DRIVE_PACO_PATH}\")\n",
        "    print(\"  Por favor, ajusta DRIVE_PACO_PATH con la ruta correcta\")\n",
        "    print(\"\\n  Para encontrar tu carpeta, puedes listar:\")\n",
        "    print(\"  !ls /content/drive/MyDrive/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copiar PACO-master a /content para mejor rendimiento\n",
        "# (Opcional pero recomendado: trabajar desde /content es más rápido que desde Drive)\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "CONTENT_PACO_PATH = '/content/PACO-master'\n",
        "\n",
        "# Si ya existe en /content, eliminarlo primero\n",
        "if Path(CONTENT_PACO_PATH).exists():\n",
        "    print(\"Eliminando copia anterior en /content...\")\n",
        "    shutil.rmtree(CONTENT_PACO_PATH)\n",
        "\n",
        "# Copiar desde Drive a /content\n",
        "print(f\"Copiando {DRIVE_PACO_PATH} a {CONTENT_PACO_PATH}...\")\n",
        "print(\"Esto puede tardar unos minutos dependiendo del tamaño...\")\n",
        "\n",
        "shutil.copytree(DRIVE_PACO_PATH, CONTENT_PACO_PATH)\n",
        "\n",
        "print(f\"✓ Copia completada\")\n",
        "print(f\"  PACO-master ahora disponible en: {CONTENT_PACO_PATH}\")\n",
        "\n",
        "# Verificar estructura\n",
        "paco_path = Path(CONTENT_PACO_PATH)\n",
        "if (paco_path / 'paco').exists():\n",
        "    print(\"✓ Estructura correcta: carpeta 'paco' encontrada\")\n",
        "else:\n",
        "    print(\"⚠ Advertencia: estructura puede estar incorrecta\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar dependencias necesarias\n",
        "# Ejecuta esta celda solo si es la primera vez o si faltan librerías\n",
        "\n",
        "print(\"Instalando/verificando dependencias...\")\n",
        "\n",
        "# PyTorch (ya viene en Colab, pero verificamos)\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"✓ PyTorch {torch.__version__} ya instalado\")\n",
        "except ImportError:\n",
        "    print(\"Instalando PyTorch...\")\n",
        "    !pip install torch\n",
        "\n",
        "# Otras dependencias\n",
        "dependencies = ['scipy', 'joblib', 'matplotlib', 'numpy', 'astropy']\n",
        "\n",
        "for dep in dependencies:\n",
        "    try:\n",
        "        __import__(dep)\n",
        "        print(f\"✓ {dep} ya instalado\")\n",
        "    except ImportError:\n",
        "        print(f\"Instalando {dep}...\")\n",
        "        !pip install {dep}\n",
        "\n",
        "print(\"\\n✓ Todas las dependencias están disponibles\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar librerías necesarias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Configurar paths\n",
        "# Prioridad: 1) /content (si se copió desde Drive), 2) Drive directo, 3) otros paths\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Intentar diferentes paths en orden de prioridad\n",
        "possible_paths = [\n",
        "    Path('/content/PACO-master'),  # Si se copió desde Drive (recomendado)\n",
        "    Path('/content/drive/MyDrive/PACO-master'),  # Directo desde Drive\n",
        "    Path('../PACO-master'),  # Path relativo\n",
        "    Path('./PACO-master'),  # Path local\n",
        "]\n",
        "\n",
        "paco_master_path = None\n",
        "for path in possible_paths:\n",
        "    if path.exists():\n",
        "        paco_master_path = path\n",
        "        print(f\"✓ PACO-master encontrado en: {path}\")\n",
        "        break\n",
        "\n",
        "if paco_master_path is None:\n",
        "    print(\"⚠ No se encontró PACO-master en ningún path conocido\")\n",
        "    print(\"  Por favor, ejecuta las celdas anteriores para montar Drive y copiar archivos\")\n",
        "    print(\"  O ajusta manualmente el path:\")\n",
        "    print(\"  paco_master_path = Path('/ruta/a/tu/PACO-master')\")\n",
        "else:\n",
        "    print(f\"  Usando: {paco_master_path.absolute()}\")\n",
        "\n",
        "vip_master_path = Path('../VIP-master')\n",
        "\n",
        "# Agregar paths al sys.path para importar módulos\n",
        "if str(paco_master_path) not in sys.path:\n",
        "    sys.path.insert(0, str(paco_master_path))\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DETECCIÓN DE HARDWARE Y LIBRERÍAS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Detectar PyTorch y GPU\n",
        "try:\n",
        "    import torch\n",
        "    PYTORCH_AVAILABLE = True\n",
        "    print(f\"✓ PyTorch disponible (versión: {torch.__version__})\")\n",
        "    \n",
        "    # Detectar GPU\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"✓ GPU CUDA disponible: {gpu_name}\")\n",
        "        print(f\"  Memoria GPU: {gpu_memory:.1f} GB\")\n",
        "        GPU_AVAILABLE = True\n",
        "        DEVICE_TYPE = 'cuda'\n",
        "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        print(\"✓ Apple Silicon GPU (MPS) disponible\")\n",
        "        GPU_AVAILABLE = True\n",
        "        DEVICE_TYPE = 'mps'\n",
        "    else:\n",
        "        print(\"⚠ GPU no disponible, usando CPU\")\n",
        "        GPU_AVAILABLE = False\n",
        "        DEVICE_TYPE = 'cpu'\n",
        "except ImportError:\n",
        "    PYTORCH_AVAILABLE = False\n",
        "    GPU_AVAILABLE = False\n",
        "    DEVICE_TYPE = 'cpu'\n",
        "    print(\"⚠ PyTorch no disponible. Instala con: pip install torch\")\n",
        "\n",
        "# Intentar importar VIP\n",
        "try:\n",
        "    import vip_hci as vip\n",
        "    VIP_AVAILABLE = True\n",
        "    vip_version = vip.__version__ if hasattr(vip, '__version__') else 'desconocida'\n",
        "    print(f\"✓ VIP disponible (versión: {vip_version})\")\n",
        "except ImportError:\n",
        "    VIP_AVAILABLE = False\n",
        "    print(\"⚠ VIP no disponible, solo se ejecutará PACO-master optimizado\")\n",
        "\n",
        "# Importar PACO-master optimizado (CPU)\n",
        "try:\n",
        "    from paco.processing.fullpaco import FullPACO as PACOOptimized\n",
        "    PACO_OPTIMIZED_AVAILABLE = True\n",
        "    print(\"✓ PACO-master optimizado (CPU) disponible\")\n",
        "except ImportError as e:\n",
        "    PACO_OPTIMIZED_AVAILABLE = False\n",
        "    print(f\"⚠ Error importando PACO-master optimizado: {e}\")\n",
        "\n",
        "# Importar FastPACO PyTorch (GPU)\n",
        "try:\n",
        "    from paco.processing.fastpaco_pytorch import FastPACO_PyTorch\n",
        "    FASTPACO_PYTORCH_AVAILABLE = True\n",
        "    print(\"✓ FastPACO PyTorch (GPU) disponible\")\n",
        "except ImportError as e:\n",
        "    FASTPACO_PYTORCH_AVAILABLE = False\n",
        "    print(f\"⚠ Error importando FastPACO PyTorch: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESUMEN DE CONFIGURACIÓN\")\n",
        "print(\"=\"*60)\n",
        "print(f\"PyTorch: {'✓' if PYTORCH_AVAILABLE else '✗'}\")\n",
        "print(f\"GPU: {'✓' if GPU_AVAILABLE else '✗'} ({DEVICE_TYPE})\")\n",
        "print(f\"VIP: {'✓' if VIP_AVAILABLE else '✗'}\")\n",
        "print(f\"PACO CPU Optimizado: {'✓' if PACO_OPTIMIZED_AVAILABLE else '✗'}\")\n",
        "print(f\"FastPACO PyTorch GPU: {'✓' if FASTPACO_PYTORCH_AVAILABLE else '✗'}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cargar Datos de Prueba\n",
        "\n",
        "Usaremos datos sintéticos o reales disponibles en el repositorio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para cargar datos\n",
        "def load_test_data():\n",
        "    \"\"\"Cargar datos de prueba desde PACO-master o generar sintéticos\"\"\"\n",
        "    \n",
        "    # Intentar cargar datos reales del testData\n",
        "    test_data_path = paco_master_path / 'testData' / 'HCI_data'\n",
        "    \n",
        "    if (test_data_path / 'images.fits').exists():\n",
        "        try:\n",
        "            from astropy.io import fits\n",
        "            cube = fits.getdata(test_data_path / 'images.fits')\n",
        "            print(f\"✓ Datos cargados desde {test_data_path}\")\n",
        "            print(f\"  Shape del cube: {cube.shape}\")\n",
        "            \n",
        "            # Cargar ángulos de paralaje\n",
        "            if (test_data_path / 'parang.dat').exists():\n",
        "                pa = np.loadtxt(test_data_path / 'parang.dat')\n",
        "            else:\n",
        "                # Generar ángulos sintéticos si no están disponibles\n",
        "                pa = np.linspace(0, 90, cube.shape[0])\n",
        "                print(\"  ⚠ Ángulos generados sintéticamente\")\n",
        "            \n",
        "            # Generar PSF sintético simple (gaussiano)\n",
        "            psf_size = 21\n",
        "            center = psf_size // 2\n",
        "            y, x = np.ogrid[:psf_size, :psf_size]\n",
        "            psf = np.exp(-((x - center)**2 + (y - center)**2) / (2 * 2.0**2))\n",
        "            psf = psf / np.sum(psf)\n",
        "            \n",
        "            return cube, pa, psf, 0.027  # pixel scale típico para NACO\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"⚠ Error cargando datos reales: {e}\")\n",
        "            print(\"  Generando datos sintéticos...\")\n",
        "    \n",
        "    # Generar datos sintéticos si no hay datos reales\n",
        "    print(\"Generando datos sintéticos para prueba...\")\n",
        "    n_frames = 20\n",
        "    img_size = 64\n",
        "    cube = np.random.randn(n_frames, img_size, img_size) * 0.1\n",
        "    pa = np.linspace(0, 90, n_frames)\n",
        "    \n",
        "    # PSF gaussiano\n",
        "    psf_size = 21\n",
        "    center = psf_size // 2\n",
        "    y, x = np.ogrid[:psf_size, :psf_size]\n",
        "    psf = np.exp(-((x - center)**2 + (y - center)**2) / (2 * 2.0**2))\n",
        "    psf = psf / np.sum(psf)\n",
        "    \n",
        "    return cube, pa, psf, 0.027\n",
        "\n",
        "# Cargar datos\n",
        "cube, pa, psf, pixscale = load_test_data()\n",
        "print(f\"\\nDatos cargados:\")\n",
        "print(f\"  Cube shape: {cube.shape}\")\n",
        "print(f\"  Ángulos: {len(pa)} frames\")\n",
        "print(f\"  PSF shape: {psf.shape}\")\n",
        "print(f\"  Pixel scale: {pixscale} arcsec/pixel\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Ejecutar PACO-master Optimizado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Opcional: Cargar Datos desde Google Drive\n",
        "\n",
        "Si tienes datos de prueba (cubes, PSF, etc.) en Google Drive, puedes cargarlos aquí.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos desde Google Drive (Opcional)\n",
        "# Descomenta y ajusta las rutas si tienes datos en Drive\n",
        "\n",
        "# Ejemplo de paths en Drive (ajusta según tu estructura):\n",
        "# DRIVE_DATA_PATH = '/content/drive/MyDrive/Tesis/Datos'\n",
        "# DRIVE_DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/Datos'\n",
        "\n",
        "# Si quieres usar datos desde Drive, descomenta lo siguiente:\n",
        "\"\"\"\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "\n",
        "# Cargar cube\n",
        "cube_path = f'{DRIVE_DATA_PATH}/naco_betapic_cube.fits'\n",
        "cube = fits.getdata(cube_path)\n",
        "\n",
        "# Cargar ángulos de paralaje\n",
        "pa_path = f'{DRIVE_DATA_PATH}/naco_betapic_pa.fits'\n",
        "pa = fits.getdata(pa_path)\n",
        "\n",
        "# Cargar PSF\n",
        "psf_path = f'{DRIVE_DATA_PATH}/naco_betapic_psf.fits'\n",
        "psf = fits.getdata(psf_path)\n",
        "\n",
        "# Pixel scale (ajustar según tu instrumento)\n",
        "pixscale = 0.027  # arcsec/pixel para NACO\n",
        "\n",
        "print(f\"✓ Datos cargados desde Drive:\")\n",
        "print(f\"  Cube shape: {cube.shape}\")\n",
        "print(f\"  Ángulos: {len(pa)} frames\")\n",
        "print(f\"  PSF shape: {psf.shape}\")\n",
        "\"\"\"\n",
        "\n",
        "# Por defecto, el notebook generará datos sintéticos si no se cargan desde Drive\n",
        "print(\"Nota: Si no cargas datos aquí, el notebook generará datos sintéticos automáticamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar coordenadas de píxeles a procesar\n",
        "img_size = cube.shape[1]\n",
        "center = img_size // 2\n",
        "test_radius = min(15, center - 5)  # Radio de prueba (aumentado para mejor comparación)\n",
        "\n",
        "# Crear grid de píxeles a procesar\n",
        "y_coords, x_coords = np.meshgrid(\n",
        "    np.arange(center - test_radius, center + test_radius),\n",
        "    np.arange(center - test_radius, center + test_radius)\n",
        ")\n",
        "phi0s = np.column_stack((x_coords.flatten(), y_coords.flatten()))\n",
        "\n",
        "print(f\"Configuración de prueba:\")\n",
        "print(f\"  Píxeles a procesar: {len(phi0s)}\")\n",
        "print(f\"  Región: {2*test_radius}×{2*test_radius} píxeles\")\n",
        "print(f\"  Centro: ({center}, {center})\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2.1 Ejecutar PACO-master Optimizado (CPU)\n",
        "# ============================================================================\n",
        "\n",
        "results_paco_cpu = None\n",
        "if PACO_OPTIMIZED_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EJECUTANDO PACO-master OPTIMIZADO (CPU)\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    try:\n",
        "        paco_opt = PACOOptimized(\n",
        "            image_stack=cube,\n",
        "            angles=pa,\n",
        "            psf=psf,\n",
        "            psf_rad=4,\n",
        "            px_scale=pixscale,\n",
        "            res_scale=1,\n",
        "            patch_area=49\n",
        "        )\n",
        "        \n",
        "        print(f\"  Procesando {len(phi0s)} píxeles...\")\n",
        "        \n",
        "        # Ejecutar con 1 core (secuencial)\n",
        "        print(f\"  Usando 1 core (secuencial)...\")\n",
        "        start_time = time.time()\n",
        "        a_opt_seq, b_opt_seq = paco_opt.PACOCalc(phi0s, cpu=1)\n",
        "        time_opt_seq = time.time() - start_time\n",
        "        print(f\"  ✓ Tiempo secuencial: {time_opt_seq:.2f} segundos\")\n",
        "        \n",
        "        # Ejecutar con múltiples cores\n",
        "        import multiprocessing\n",
        "        n_cores = min(8, multiprocessing.cpu_count())\n",
        "        print(f\"  Procesando con {n_cores} cores (paralelo)...\")\n",
        "        start_time = time.time()\n",
        "        a_opt_par, b_opt_par = paco_opt.PACOCalc(phi0s, cpu=n_cores)\n",
        "        time_opt_par = time.time() - start_time\n",
        "        print(f\"  ✓ Tiempo paralelo ({n_cores} cores): {time_opt_par:.2f} segundos\")\n",
        "        if time_opt_par > 0:\n",
        "            print(f\"  ✓ Speedup: {time_opt_seq/time_opt_par:.2f}x\")\n",
        "        \n",
        "        # Calcular SNR map\n",
        "        snr_opt = b_opt_par / np.sqrt(a_opt_par)\n",
        "        snr_opt_2d = snr_opt.reshape(x_coords.shape)\n",
        "        \n",
        "        results_paco_cpu = {\n",
        "            'a': a_opt_par,\n",
        "            'b': b_opt_par,\n",
        "            'snr': snr_opt_2d,\n",
        "            'time_seq': time_opt_seq,\n",
        "            'time_par': time_opt_par,\n",
        "            'speedup': time_opt_seq/time_opt_par if time_opt_par > 0 else 0,\n",
        "            'n_pixels': len(phi0s),\n",
        "            'method': 'CPU Optimized'\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error ejecutando PACO-master optimizado: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        results_paco_cpu = None\n",
        "else:\n",
        "    print(\"PACO-master optimizado (CPU) no disponible\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2.2 Ejecutar FastPACO PyTorch (GPU)\n",
        "# ============================================================================\n",
        "\n",
        "results_paco_gpu = None\n",
        "if FASTPACO_PYTORCH_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EJECUTANDO FastPACO PYTORCH (GPU)\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    try:\n",
        "        # Crear instancia de FastPACO PyTorch\n",
        "        paco_gpu = FastPACO_PyTorch(\n",
        "            image_stack=cube,\n",
        "            angles=pa,\n",
        "            psf=psf,\n",
        "            psf_rad=4,\n",
        "            px_scale=pixscale,\n",
        "            res_scale=1,\n",
        "            patch_area=49\n",
        "        )\n",
        "        \n",
        "        print(f\"  Procesando {len(phi0s)} píxeles...\")\n",
        "        print(f\"  Dispositivo: {paco_gpu.device}\")\n",
        "        \n",
        "        # Ejecutar con GPU\n",
        "        print(f\"  Ejecutando en {DEVICE_TYPE.upper()}...\")\n",
        "        start_time = time.time()\n",
        "        a_gpu, b_gpu = paco_gpu.PACOCalc(phi0s, use_gpu=GPU_AVAILABLE, batch_mode=False)\n",
        "        time_gpu = time.time() - start_time\n",
        "        print(f\"  ✓ Tiempo GPU: {time_gpu:.2f} segundos\")\n",
        "        \n",
        "        # Si hay resultados CPU, calcular speedup\n",
        "        if results_paco_cpu is not None and time_gpu > 0:\n",
        "            speedup_vs_cpu = results_paco_cpu['time_par'] / time_gpu\n",
        "            print(f\"  ✓ Speedup vs CPU paralelo: {speedup_vs_cpu:.2f}x\")\n",
        "        \n",
        "        # Calcular SNR map\n",
        "        snr_gpu = b_gpu / np.sqrt(a_gpu)\n",
        "        snr_gpu_2d = snr_gpu.reshape(x_coords.shape)\n",
        "        \n",
        "        results_paco_gpu = {\n",
        "            'a': a_gpu,\n",
        "            'b': b_gpu,\n",
        "            'snr': snr_gpu_2d,\n",
        "            'time': time_gpu,\n",
        "            'n_pixels': len(phi0s),\n",
        "            'method': f'PyTorch {DEVICE_TYPE.upper()}',\n",
        "            'device': str(paco_gpu.device)\n",
        "        }\n",
        "        \n",
        "        # Si GPU disponible, probar también batch mode\n",
        "        if GPU_AVAILABLE:\n",
        "            print(f\"\\n  Probando batch mode (ultra-optimizado)...\")\n",
        "            start_time = time.time()\n",
        "            a_gpu_batch, b_gpu_batch = paco_gpu.PACOCalc(phi0s, use_gpu=True, batch_mode=True)\n",
        "            time_gpu_batch = time.time() - start_time\n",
        "            print(f\"  ✓ Tiempo GPU (batch mode): {time_gpu_batch:.2f} segundos\")\n",
        "            if time_gpu_batch > 0:\n",
        "                speedup_batch = time_gpu / time_gpu_batch\n",
        "                print(f\"  ✓ Speedup batch vs normal: {speedup_batch:.2f}x\")\n",
        "                results_paco_gpu['time_batch'] = time_gpu_batch\n",
        "                results_paco_gpu['speedup_batch'] = speedup_batch\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error ejecutando FastPACO PyTorch: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        results_paco_gpu = None\n",
        "else:\n",
        "    print(\"FastPACO PyTorch no disponible\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Ejecutar VIP-master PACO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if VIP_AVAILABLE:\n",
        "    print(\"Ejecutando VIP-master PACO...\")\n",
        "    \n",
        "    try:\n",
        "        from vip_hci.invprob.paco import FullPACO as VIPFullPACO\n",
        "        \n",
        "        # Crear instancia de VIP FullPACO\n",
        "        vip_paco = VIPFullPACO(\n",
        "            cube=cube,\n",
        "            angles=pa,\n",
        "            psf=psf,\n",
        "            fwhm=4.0,\n",
        "            pixscale=pixscale,\n",
        "            verbose=True\n",
        "        )\n",
        "        \n",
        "        # Ejecutar PACO\n",
        "        print(\"  Ejecutando cálculo...\")\n",
        "        start_time = time.time()\n",
        "        snr_vip, flux_vip = vip_paco.run(cpu=1, use_subpixel_psf_astrometry=False)\n",
        "        time_vip = time.time() - start_time\n",
        "        \n",
        "        print(f\"  ✓ Tiempo VIP: {time_vip:.2f} segundos\")\n",
        "        \n",
        "        results_vip = {\n",
        "            'snr': snr_vip,\n",
        "            'flux': flux_vip,\n",
        "            'time': time_vip\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error ejecutando VIP PACO: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        results_vip = None\n",
        "else:\n",
        "    print(\"VIP no disponible\")\n",
        "    results_vip = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Comparación de Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear visualización comparativa\n",
        "n_plots = sum([results_paco_cpu is not None, results_paco_gpu is not None, results_vip is not None])\n",
        "if n_plots == 0:\n",
        "    print(\"No hay resultados para visualizar\")\n",
        "else:\n",
        "    fig, axes = plt.subplots(1, n_plots, figsize=(6*n_plots, 5))\n",
        "    if n_plots == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    plot_idx = 0\n",
        "    \n",
        "    # PACO CPU Optimizado\n",
        "    if results_paco_cpu is not None:\n",
        "        im = axes[plot_idx].imshow(results_paco_cpu['snr'], origin='lower', cmap='hot')\n",
        "        axes[plot_idx].set_title(f'PACO CPU Optimizado\\n({results_paco_cpu[\"time_par\"]:.2f}s)', fontsize=11)\n",
        "        axes[plot_idx].set_xlabel('X (pixels)')\n",
        "        axes[plot_idx].set_ylabel('Y (pixels)')\n",
        "        plt.colorbar(im, ax=axes[plot_idx], label='SNR')\n",
        "        plot_idx += 1\n",
        "    \n",
        "    # PACO GPU PyTorch\n",
        "    if results_paco_gpu is not None:\n",
        "        im = axes[plot_idx].imshow(results_paco_gpu['snr'], origin='lower', cmap='hot')\n",
        "        title = f'FastPACO PyTorch {results_paco_gpu[\"device\"]}\\n({results_paco_gpu[\"time\"]:.2f}s)'\n",
        "        if 'time_batch' in results_paco_gpu:\n",
        "            title += f'\\nBatch: {results_paco_gpu[\"time_batch\"]:.2f}s'\n",
        "        axes[plot_idx].set_title(title, fontsize=11)\n",
        "        axes[plot_idx].set_xlabel('X (pixels)')\n",
        "        axes[plot_idx].set_ylabel('Y (pixels)')\n",
        "        plt.colorbar(im, ax=axes[plot_idx], label='SNR')\n",
        "        plot_idx += 1\n",
        "    \n",
        "    # VIP\n",
        "    if results_vip is not None:\n",
        "        im = axes[plot_idx].imshow(results_vip['snr'], origin='lower', cmap='hot')\n",
        "        axes[plot_idx].set_title(f'VIP-master PACO\\n({results_vip[\"time\"]:.2f}s)', fontsize=11)\n",
        "        axes[plot_idx].set_xlabel('X (pixels)')\n",
        "        axes[plot_idx].set_ylabel('Y (pixels)')\n",
        "        plt.colorbar(im, ax=axes[plot_idx], label='SNR')\n",
        "        plot_idx += 1\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Resumen numérico\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESUMEN DE COMPARACIÓN\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if results_paco_cpu is not None:\n",
        "    print(f\"\\nPACO-master Optimizado (CPU):\")\n",
        "    print(f\"  Tiempo secuencial: {results_paco_cpu['time_seq']:.2f}s\")\n",
        "    print(f\"  Tiempo paralelo:   {results_paco_cpu['time_par']:.2f}s\")\n",
        "    print(f\"  Speedup interno:  {results_paco_cpu['speedup']:.2f}x\")\n",
        "    print(f\"  Píxeles:           {results_paco_cpu['n_pixels']}\")\n",
        "    print(f\"  SNR máximo:        {np.nanmax(results_paco_cpu['snr']):.2f}\")\n",
        "\n",
        "if results_paco_gpu is not None:\n",
        "    print(f\"\\nFastPACO PyTorch ({results_paco_gpu['device']}):\")\n",
        "    print(f\"  Tiempo:            {results_paco_gpu['time']:.2f}s\")\n",
        "    if 'time_batch' in results_paco_gpu:\n",
        "        print(f\"  Tiempo (batch):    {results_paco_gpu['time_batch']:.2f}s\")\n",
        "        print(f\"  Speedup batch:    {results_paco_gpu['speedup_batch']:.2f}x\")\n",
        "    print(f\"  Píxeles:           {results_paco_gpu['n_pixels']}\")\n",
        "    print(f\"  SNR máximo:        {np.nanmax(results_paco_gpu['snr']):.2f}\")\n",
        "    \n",
        "    # Comparación con CPU\n",
        "    if results_paco_cpu is not None and results_paco_gpu['time'] > 0:\n",
        "        speedup_vs_cpu = results_paco_cpu['time_par'] / results_paco_gpu['time']\n",
        "        print(f\"  Speedup vs CPU:    {speedup_vs_cpu:.2f}x\")\n",
        "\n",
        "if results_vip is not None:\n",
        "    print(f\"\\nVIP-master PACO:\")\n",
        "    print(f\"  Tiempo:            {results_vip['time']:.2f}s\")\n",
        "    print(f\"  SNR máximo:        {np.nanmax(results_vip['snr']):.2f}\")\n",
        "    \n",
        "    # Comparación con CPU\n",
        "    if results_paco_cpu is not None and results_vip['time'] > 0:\n",
        "        speedup_vs_cpu = results_paco_cpu['time_par'] / results_vip['time']\n",
        "        print(f\"  Speedup vs CPU:    {speedup_vs_cpu:.2f}x\")\n",
        "    \n",
        "    # Comparación con GPU\n",
        "    if results_paco_gpu is not None and results_vip['time'] > 0:\n",
        "        speedup_vs_gpu = results_vip['time'] / results_paco_gpu['time']\n",
        "        print(f\"  Speedup vs GPU:    {speedup_vs_gpu:.2f}x\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Validación de Precisión Numérica\n",
        "\n",
        "Verificamos que las optimizaciones no comprometen la precisión científica del algoritmo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validación de precisión numérica\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VALIDACIÓN DE PRECISIÓN NUMÉRICA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Validar CPU\n",
        "if results_paco_cpu is not None:\n",
        "    print(\"\\n1. PACO CPU Optimizado:\")\n",
        "    has_nan = np.any(np.isnan(results_paco_cpu['snr']))\n",
        "    has_inf = np.any(np.isinf(results_paco_cpu['snr']))\n",
        "    print(f\"   NaN: {has_nan}, Inf: {has_inf}\")\n",
        "    if not has_nan and not has_inf:\n",
        "        print(\"   ✓ Valores numéricos válidos\")\n",
        "    \n",
        "    a_valid = results_paco_cpu['a'][~np.isnan(results_paco_cpu['a'])]\n",
        "    if len(a_valid) > 0 and np.all(a_valid > 0):\n",
        "        print(\"   ✓ Valores de 'a' positivos (correcto)\")\n",
        "\n",
        "# Validar GPU\n",
        "if results_paco_gpu is not None:\n",
        "    print(\"\\n2. FastPACO PyTorch GPU:\")\n",
        "    has_nan = np.any(np.isnan(results_paco_gpu['snr']))\n",
        "    has_inf = np.any(np.isinf(results_paco_gpu['snr']))\n",
        "    print(f\"   NaN: {has_nan}, Inf: {has_inf}\")\n",
        "    if not has_nan and not has_inf:\n",
        "        print(\"   ✓ Valores numéricos válidos\")\n",
        "    \n",
        "    a_valid = results_paco_gpu['a'][~np.isnan(results_paco_gpu['a'])]\n",
        "    if len(a_valid) > 0 and np.all(a_valid > 0):\n",
        "        print(\"   ✓ Valores de 'a' positivos (correcto)\")\n",
        "    \n",
        "    # Comparar con CPU si ambos están disponibles\n",
        "    if results_paco_cpu is not None:\n",
        "        # Comparar SNR maps (deben ser similares)\n",
        "        snr_cpu = results_paco_cpu['snr']\n",
        "        snr_gpu = results_paco_gpu['snr']\n",
        "        diff = np.abs(snr_cpu - snr_gpu)\n",
        "        max_diff = np.nanmax(diff)\n",
        "        mean_diff = np.nanmean(diff)\n",
        "        print(f\"\\n   Comparación CPU vs GPU:\")\n",
        "        print(f\"   Diferencia máxima: {max_diff:.6f}\")\n",
        "        print(f\"   Diferencia media:  {mean_diff:.6f}\")\n",
        "        if max_diff < 0.01:  # Tolerancia del 1%\n",
        "            print(\"   ✓ Resultados consistentes entre CPU y GPU\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VALIDACIÓN COMPLETA\")\n",
        "print(\"=\"*70)\n",
        "print(\"Las optimizaciones mantienen la precisión numérica.\")\n",
        "print(\"Los resultados son consistentes y válidos para uso científico.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
